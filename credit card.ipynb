{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "Scikit-learn: 0.24.0\n",
      "Pandas: 1.0.1\n",
      "Numpy: 1.19.5\n",
      "seaborn: 0.10.0\n",
      "matplotlib: 3.1.3\n"
     ]
    }
   ],
   "source": [
    "import sys    #for python version\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "import seaborn\n",
    "import matplotlib\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))\n",
    "print('seaborn: {}'.format(seaborn.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Python27\\anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#importing all the required ML packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score #for confusion matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, f1_score, recall_score\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "# To ignore all the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Display all the columns of the dataframe\n",
    "pd.pandas.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset from the location\n",
    "df=pd.read_csv('TRAIN.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.245295</td>\n",
       "      <td>-1.160960</td>\n",
       "      <td>-1.966682</td>\n",
       "      <td>-1.430190</td>\n",
       "      <td>-0.607246</td>\n",
       "      <td>-1.508696</td>\n",
       "      <td>-0.074415</td>\n",
       "      <td>-0.655096</td>\n",
       "      <td>-1.970141</td>\n",
       "      <td>1.607283</td>\n",
       "      <td>-0.780267</td>\n",
       "      <td>-0.294928</td>\n",
       "      <td>1.236719</td>\n",
       "      <td>-0.135565</td>\n",
       "      <td>-0.832677</td>\n",
       "      <td>-1.400205</td>\n",
       "      <td>0.807960</td>\n",
       "      <td>-0.670317</td>\n",
       "      <td>-0.044106</td>\n",
       "      <td>-0.292081</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.521714</td>\n",
       "      <td>-0.064971</td>\n",
       "      <td>0.048849</td>\n",
       "      <td>0.383290</td>\n",
       "      <td>0.103970</td>\n",
       "      <td>-0.047350</td>\n",
       "      <td>-0.064800</td>\n",
       "      <td>74.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.278609</td>\n",
       "      <td>0.102574</td>\n",
       "      <td>0.512079</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>-0.723474</td>\n",
       "      <td>-1.334105</td>\n",
       "      <td>0.029958</td>\n",
       "      <td>-0.296595</td>\n",
       "      <td>0.128119</td>\n",
       "      <td>-0.209865</td>\n",
       "      <td>0.188511</td>\n",
       "      <td>0.674525</td>\n",
       "      <td>0.712608</td>\n",
       "      <td>0.122319</td>\n",
       "      <td>1.038024</td>\n",
       "      <td>0.128638</td>\n",
       "      <td>-0.222614</td>\n",
       "      <td>-0.687546</td>\n",
       "      <td>-0.056504</td>\n",
       "      <td>-0.040015</td>\n",
       "      <td>-0.081470</td>\n",
       "      <td>-0.182506</td>\n",
       "      <td>0.078986</td>\n",
       "      <td>0.789993</td>\n",
       "      <td>0.219794</td>\n",
       "      <td>0.938359</td>\n",
       "      <td>-0.078720</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.466457</td>\n",
       "      <td>0.026088</td>\n",
       "      <td>-0.499298</td>\n",
       "      <td>-0.674372</td>\n",
       "      <td>-0.144883</td>\n",
       "      <td>-1.178075</td>\n",
       "      <td>0.058089</td>\n",
       "      <td>-0.420145</td>\n",
       "      <td>-1.359651</td>\n",
       "      <td>0.210249</td>\n",
       "      <td>-0.033777</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>1.767471</td>\n",
       "      <td>-1.212943</td>\n",
       "      <td>0.427684</td>\n",
       "      <td>1.252714</td>\n",
       "      <td>0.843412</td>\n",
       "      <td>-1.534474</td>\n",
       "      <td>0.830734</td>\n",
       "      <td>0.207653</td>\n",
       "      <td>-0.234087</td>\n",
       "      <td>-0.710542</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>-0.174713</td>\n",
       "      <td>0.533719</td>\n",
       "      <td>-0.454779</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.030935</td>\n",
       "      <td>10.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.922137</td>\n",
       "      <td>-0.371579</td>\n",
       "      <td>2.132018</td>\n",
       "      <td>-0.796997</td>\n",
       "      <td>0.324175</td>\n",
       "      <td>-1.162006</td>\n",
       "      <td>0.277208</td>\n",
       "      <td>-0.249586</td>\n",
       "      <td>-0.775648</td>\n",
       "      <td>-0.061757</td>\n",
       "      <td>-0.959725</td>\n",
       "      <td>0.408746</td>\n",
       "      <td>0.597641</td>\n",
       "      <td>-0.802430</td>\n",
       "      <td>-1.889520</td>\n",
       "      <td>-1.607785</td>\n",
       "      <td>-0.401475</td>\n",
       "      <td>0.729773</td>\n",
       "      <td>-2.445693</td>\n",
       "      <td>-0.461062</td>\n",
       "      <td>-0.302654</td>\n",
       "      <td>-0.246899</td>\n",
       "      <td>-0.045745</td>\n",
       "      <td>0.677110</td>\n",
       "      <td>0.016109</td>\n",
       "      <td>-0.734220</td>\n",
       "      <td>-0.034480</td>\n",
       "      <td>-0.064786</td>\n",
       "      <td>8.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.166525</td>\n",
       "      <td>0.255439</td>\n",
       "      <td>2.108464</td>\n",
       "      <td>0.135019</td>\n",
       "      <td>-0.072979</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>0.755918</td>\n",
       "      <td>0.355528</td>\n",
       "      <td>-0.422820</td>\n",
       "      <td>-0.842826</td>\n",
       "      <td>0.663538</td>\n",
       "      <td>0.624657</td>\n",
       "      <td>0.107262</td>\n",
       "      <td>-0.073654</td>\n",
       "      <td>-0.305506</td>\n",
       "      <td>0.618642</td>\n",
       "      <td>-0.952529</td>\n",
       "      <td>0.757618</td>\n",
       "      <td>-0.375461</td>\n",
       "      <td>0.353355</td>\n",
       "      <td>0.136470</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>0.121017</td>\n",
       "      <td>0.636266</td>\n",
       "      <td>0.492943</td>\n",
       "      <td>-0.750242</td>\n",
       "      <td>0.029124</td>\n",
       "      <td>0.091303</td>\n",
       "      <td>175.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "Index                                                                         \n",
       "0      2.245295 -1.160960 -1.966682 -1.430190 -0.607246 -1.508696 -0.074415   \n",
       "1      1.278609  0.102574  0.512079  0.003930 -0.723474 -1.334105  0.029958   \n",
       "2      1.466457  0.026088 -0.499298 -0.674372 -0.144883 -1.178075  0.058089   \n",
       "3     -0.922137 -0.371579  2.132018 -0.796997  0.324175 -1.162006  0.277208   \n",
       "4     -1.166525  0.255439  2.108464  0.135019 -0.072979  0.910821  0.755918   \n",
       "\n",
       "             V8        V9       V10       V11       V12       V13       V14  \\\n",
       "Index                                                                         \n",
       "0     -0.655096 -1.970141  1.607283 -0.780267 -0.294928  1.236719 -0.135565   \n",
       "1     -0.296595  0.128119 -0.209865  0.188511  0.674525  0.712608  0.122319   \n",
       "2     -0.420145 -1.359651  0.210249 -0.033777 -0.001594  1.767471 -1.212943   \n",
       "3     -0.249586 -0.775648 -0.061757 -0.959725  0.408746  0.597641 -0.802430   \n",
       "4      0.355528 -0.422820 -0.842826  0.663538  0.624657  0.107262 -0.073654   \n",
       "\n",
       "            V15       V16       V17       V18       V19       V20       V21  \\\n",
       "Index                                                                         \n",
       "0     -0.832677 -1.400205  0.807960 -0.670317 -0.044106 -0.292081  0.010490   \n",
       "1      1.038024  0.128638 -0.222614 -0.687546 -0.056504 -0.040015 -0.081470   \n",
       "2      0.427684  1.252714  0.843412 -1.534474  0.830734  0.207653 -0.234087   \n",
       "3     -1.889520 -1.607785 -0.401475  0.729773 -2.445693 -0.461062 -0.302654   \n",
       "4     -0.305506  0.618642 -0.952529  0.757618 -0.375461  0.353355  0.136470   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Index                                                                         \n",
       "0      0.521714 -0.064971  0.048849  0.383290  0.103970 -0.047350 -0.064800   \n",
       "1     -0.182506  0.078986  0.789993  0.219794  0.938359 -0.078720  0.008119   \n",
       "2     -0.710542 -0.001242 -0.174713  0.533719 -0.454779  0.001524  0.030935   \n",
       "3     -0.246899 -0.045745  0.677110  0.016109 -0.734220 -0.034480 -0.064786   \n",
       "4      0.017496  0.121017  0.636266  0.492943 -0.750242  0.029124  0.091303   \n",
       "\n",
       "       Amount  Class  \n",
       "Index                 \n",
       "0       74.75      0  \n",
       "1        1.38      0  \n",
       "2       10.95      0  \n",
       "3        8.04      0  \n",
       "4      175.00      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284455, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "      <td>284455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000779</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>88.359646</td>\n",
       "      <td>0.001547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.956147</td>\n",
       "      <td>1.650234</td>\n",
       "      <td>1.510626</td>\n",
       "      <td>1.414216</td>\n",
       "      <td>1.378329</td>\n",
       "      <td>1.332161</td>\n",
       "      <td>1.232971</td>\n",
       "      <td>1.190897</td>\n",
       "      <td>1.097805</td>\n",
       "      <td>1.085083</td>\n",
       "      <td>1.018770</td>\n",
       "      <td>0.993861</td>\n",
       "      <td>0.995318</td>\n",
       "      <td>0.951702</td>\n",
       "      <td>0.915289</td>\n",
       "      <td>0.872882</td>\n",
       "      <td>0.839648</td>\n",
       "      <td>0.836807</td>\n",
       "      <td>0.813859</td>\n",
       "      <td>0.771083</td>\n",
       "      <td>0.732765</td>\n",
       "      <td>0.725495</td>\n",
       "      <td>0.624473</td>\n",
       "      <td>0.605645</td>\n",
       "      <td>0.521274</td>\n",
       "      <td>0.482243</td>\n",
       "      <td>0.403488</td>\n",
       "      <td>0.330127</td>\n",
       "      <td>250.177771</td>\n",
       "      <td>0.039299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-13.563273</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-9.335193</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.920117</td>\n",
       "      <td>-0.598750</td>\n",
       "      <td>-0.889749</td>\n",
       "      <td>-0.848835</td>\n",
       "      <td>-0.691343</td>\n",
       "      <td>-0.768227</td>\n",
       "      <td>-0.553788</td>\n",
       "      <td>-0.208633</td>\n",
       "      <td>-0.642669</td>\n",
       "      <td>-0.535273</td>\n",
       "      <td>-0.762625</td>\n",
       "      <td>-0.405250</td>\n",
       "      <td>-0.648393</td>\n",
       "      <td>-0.425253</td>\n",
       "      <td>-0.582798</td>\n",
       "      <td>-0.467797</td>\n",
       "      <td>-0.483632</td>\n",
       "      <td>-0.498663</td>\n",
       "      <td>-0.456281</td>\n",
       "      <td>-0.211704</td>\n",
       "      <td>-0.228434</td>\n",
       "      <td>-0.542432</td>\n",
       "      <td>-0.161861</td>\n",
       "      <td>-0.354545</td>\n",
       "      <td>-0.317194</td>\n",
       "      <td>-0.326951</td>\n",
       "      <td>-0.070845</td>\n",
       "      <td>-0.052957</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.018330</td>\n",
       "      <td>0.065238</td>\n",
       "      <td>0.179953</td>\n",
       "      <td>-0.020206</td>\n",
       "      <td>-0.054243</td>\n",
       "      <td>-0.274172</td>\n",
       "      <td>0.040265</td>\n",
       "      <td>0.022328</td>\n",
       "      <td>-0.051183</td>\n",
       "      <td>-0.092820</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>0.140170</td>\n",
       "      <td>-0.013518</td>\n",
       "      <td>0.050731</td>\n",
       "      <td>0.048122</td>\n",
       "      <td>0.066473</td>\n",
       "      <td>-0.065577</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>-0.062480</td>\n",
       "      <td>-0.029520</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>-0.011192</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.016461</td>\n",
       "      <td>-0.052077</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.315693</td>\n",
       "      <td>0.803357</td>\n",
       "      <td>1.027332</td>\n",
       "      <td>0.742635</td>\n",
       "      <td>0.612015</td>\n",
       "      <td>0.398641</td>\n",
       "      <td>0.570515</td>\n",
       "      <td>0.327214</td>\n",
       "      <td>0.597346</td>\n",
       "      <td>0.454005</td>\n",
       "      <td>0.739251</td>\n",
       "      <td>0.618276</td>\n",
       "      <td>0.662590</td>\n",
       "      <td>0.493220</td>\n",
       "      <td>0.648842</td>\n",
       "      <td>0.523282</td>\n",
       "      <td>0.399776</td>\n",
       "      <td>0.500875</td>\n",
       "      <td>0.458768</td>\n",
       "      <td>0.133013</td>\n",
       "      <td>0.186326</td>\n",
       "      <td>0.528481</td>\n",
       "      <td>0.147659</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>0.350697</td>\n",
       "      <td>0.240929</td>\n",
       "      <td>0.091023</td>\n",
       "      <td>0.078271</td>\n",
       "      <td>77.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>23.745136</td>\n",
       "      <td>12.018913</td>\n",
       "      <td>7.848392</td>\n",
       "      <td>7.126883</td>\n",
       "      <td>10.526766</td>\n",
       "      <td>8.877742</td>\n",
       "      <td>17.315112</td>\n",
       "      <td>9.253526</td>\n",
       "      <td>5.041069</td>\n",
       "      <td>5.591971</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  V1             V2             V3             V4  \\\n",
       "count  284455.000000  284455.000000  284455.000000  284455.000000   \n",
       "mean        0.000779      -0.000811       0.001275      -0.000793   \n",
       "std         1.956147       1.650234       1.510626       1.414216   \n",
       "min       -56.407510     -72.715728     -48.325589      -5.683171   \n",
       "25%        -0.920117      -0.598750      -0.889749      -0.848835   \n",
       "50%         0.018330       0.065238       0.179953      -0.020206   \n",
       "75%         1.315693       0.803357       1.027332       0.742635   \n",
       "max         2.454930      22.057729       9.382558      16.875344   \n",
       "\n",
       "                  V5             V6             V7             V8  \\\n",
       "count  284455.000000  284455.000000  284455.000000  284455.000000   \n",
       "mean        0.000592       0.000186       0.000951      -0.000270   \n",
       "std         1.378329       1.332161       1.232971       1.190897   \n",
       "min      -113.743307     -26.160506     -43.557242     -73.216718   \n",
       "25%        -0.691343      -0.768227      -0.553788      -0.208633   \n",
       "50%        -0.054243      -0.274172       0.040265       0.022328   \n",
       "75%         0.612015       0.398641       0.570515       0.327214   \n",
       "max        34.801666      73.301626     120.589494      20.007208   \n",
       "\n",
       "                  V9            V10            V11            V12  \\\n",
       "count  284455.000000  284455.000000  284455.000000  284455.000000   \n",
       "mean        0.000505       0.000948      -0.000669       0.001013   \n",
       "std         1.097805       1.085083       1.018770       0.993861   \n",
       "min       -13.434066     -24.588262      -4.797473     -18.683715   \n",
       "25%        -0.642669      -0.535273      -0.762625      -0.405250   \n",
       "50%        -0.051183      -0.092820      -0.032963       0.140170   \n",
       "75%         0.597346       0.454005       0.739251       0.618276   \n",
       "max        15.594995      23.745136      12.018913       7.848392   \n",
       "\n",
       "                 V13            V14            V15            V16  \\\n",
       "count  284455.000000  284455.000000  284455.000000  284455.000000   \n",
       "mean        0.000120       0.001309       0.000053       0.000711   \n",
       "std         0.995318       0.951702       0.915289       0.872882   \n",
       "min        -5.791881     -19.214325      -4.498945     -13.563273   \n",
       "25%        -0.648393      -0.425253      -0.582798      -0.467797   \n",
       "50%        -0.013518       0.050731       0.048122       0.066473   \n",
       "75%         0.662590       0.493220       0.648842       0.523282   \n",
       "max         7.126883      10.526766       8.877742      17.315112   \n",
       "\n",
       "                 V17            V18            V19            V20  \\\n",
       "count  284455.000000  284455.000000  284455.000000  284455.000000   \n",
       "mean        0.001262       0.000469      -0.000116      -0.000029   \n",
       "std         0.839648       0.836807       0.813859       0.771083   \n",
       "min       -25.162799      -9.335193      -7.213527     -54.497720   \n",
       "25%        -0.483632      -0.498663      -0.456281      -0.211704   \n",
       "50%        -0.065577      -0.003506       0.003738      -0.062480   \n",
       "75%         0.399776       0.500875       0.458768       0.133013   \n",
       "max         9.253526       5.041069       5.591971      39.420904   \n",
       "\n",
       "                 V21            V22            V23            V24  \\\n",
       "count  284455.000000  284455.000000  284455.000000  284455.000000   \n",
       "mean       -0.000171      -0.000050       0.000027       0.000018   \n",
       "std         0.732765       0.725495       0.624473       0.605645   \n",
       "min       -34.830382     -10.933144     -44.807735      -2.836627   \n",
       "25%        -0.228434      -0.542432      -0.161861      -0.354545   \n",
       "50%        -0.029520       0.006675      -0.011192       0.040977   \n",
       "75%         0.186326       0.528481       0.147659       0.439527   \n",
       "max        27.202839      10.503090      22.528412       4.584549   \n",
       "\n",
       "                 V25            V26            V27            V28  \\\n",
       "count  284455.000000  284455.000000  284455.000000  284455.000000   \n",
       "mean       -0.000051       0.000028      -0.000037      -0.000028   \n",
       "std         0.521274       0.482243       0.403488       0.330127   \n",
       "min       -10.295397      -2.604551     -22.565679     -15.430084   \n",
       "25%        -0.317194      -0.326951      -0.070845      -0.052957   \n",
       "50%         0.016461      -0.052077       0.001337       0.011238   \n",
       "75%         0.350697       0.240929       0.091023       0.078271   \n",
       "max         7.519589       3.517346      31.612198      33.847808   \n",
       "\n",
       "              Amount          Class  \n",
       "count  284455.000000  284455.000000  \n",
       "mean       88.359646       0.001547  \n",
       "std       250.177771       0.039299  \n",
       "min         0.000000       0.000000  \n",
       "25%         5.600000       0.000000  \n",
       "50%        22.000000       0.000000  \n",
       "75%        77.200000       0.000000  \n",
       "max     25691.160000       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing the Structure and Summary of the data to understand the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 284455 entries, 0 to 284454\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   V1      284455 non-null  float64\n",
      " 1   V2      284455 non-null  float64\n",
      " 2   V3      284455 non-null  float64\n",
      " 3   V4      284455 non-null  float64\n",
      " 4   V5      284455 non-null  float64\n",
      " 5   V6      284455 non-null  float64\n",
      " 6   V7      284455 non-null  float64\n",
      " 7   V8      284455 non-null  float64\n",
      " 8   V9      284455 non-null  float64\n",
      " 9   V10     284455 non-null  float64\n",
      " 10  V11     284455 non-null  float64\n",
      " 11  V12     284455 non-null  float64\n",
      " 12  V13     284455 non-null  float64\n",
      " 13  V14     284455 non-null  float64\n",
      " 14  V15     284455 non-null  float64\n",
      " 15  V16     284455 non-null  float64\n",
      " 16  V17     284455 non-null  float64\n",
      " 17  V18     284455 non-null  float64\n",
      " 18  V19     284455 non-null  float64\n",
      " 19  V20     284455 non-null  float64\n",
      " 20  V21     284455 non-null  float64\n",
      " 21  V22     284455 non-null  float64\n",
      " 22  V23     284455 non-null  float64\n",
      " 23  V24     284455 non-null  float64\n",
      " 24  V25     284455 non-null  float64\n",
      " 25  V26     284455 non-null  float64\n",
      " 26  V27     284455 non-null  float64\n",
      " 27  V28     284455 non-null  float64\n",
      " 28  Amount  284455 non-null  float64\n",
      " 29  Class   284455 non-null  int64  \n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 67.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Fraudalent Transactions :  440\n",
      "Number of Non-Fraudalent Transactions :  284015\n"
     ]
    }
   ],
   "source": [
    "#Number of Fraudalent and Non-Fraudalent Transactions\n",
    "\n",
    "fraud        = df.loc[df['Class']==1]\n",
    "normal_trans = df.loc[df['Class']==0]\n",
    "\n",
    "print(\"Number of Fraudalent Transactions : \", len(fraud))\n",
    "print(\"Number of Non-Fraudalent Transactions : \", len(normal_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can observe that data is highly imbalanced as Non-Fraudalent Transactions are higher than Fraudalent so to solve this we can use smote analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Amount variable should be scaled so that all the variable will be in same scale \n",
    "scaler = StandardScaler()\n",
    "df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.245295</td>\n",
       "      <td>-1.160960</td>\n",
       "      <td>-1.966682</td>\n",
       "      <td>-1.430190</td>\n",
       "      <td>-0.607246</td>\n",
       "      <td>-1.508696</td>\n",
       "      <td>-0.074415</td>\n",
       "      <td>-0.655096</td>\n",
       "      <td>-1.970141</td>\n",
       "      <td>1.607283</td>\n",
       "      <td>-0.780267</td>\n",
       "      <td>-0.294928</td>\n",
       "      <td>1.236719</td>\n",
       "      <td>-0.135565</td>\n",
       "      <td>-0.832677</td>\n",
       "      <td>-1.400205</td>\n",
       "      <td>0.807960</td>\n",
       "      <td>-0.670317</td>\n",
       "      <td>-0.044106</td>\n",
       "      <td>-0.292081</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.521714</td>\n",
       "      <td>-0.064971</td>\n",
       "      <td>0.048849</td>\n",
       "      <td>0.383290</td>\n",
       "      <td>0.103970</td>\n",
       "      <td>-0.047350</td>\n",
       "      <td>-0.064800</td>\n",
       "      <td>-0.054400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.278609</td>\n",
       "      <td>0.102574</td>\n",
       "      <td>0.512079</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>-0.723474</td>\n",
       "      <td>-1.334105</td>\n",
       "      <td>0.029958</td>\n",
       "      <td>-0.296595</td>\n",
       "      <td>0.128119</td>\n",
       "      <td>-0.209865</td>\n",
       "      <td>0.188511</td>\n",
       "      <td>0.674525</td>\n",
       "      <td>0.712608</td>\n",
       "      <td>0.122319</td>\n",
       "      <td>1.038024</td>\n",
       "      <td>0.128638</td>\n",
       "      <td>-0.222614</td>\n",
       "      <td>-0.687546</td>\n",
       "      <td>-0.056504</td>\n",
       "      <td>-0.040015</td>\n",
       "      <td>-0.081470</td>\n",
       "      <td>-0.182506</td>\n",
       "      <td>0.078986</td>\n",
       "      <td>0.789993</td>\n",
       "      <td>0.219794</td>\n",
       "      <td>0.938359</td>\n",
       "      <td>-0.078720</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>-0.347672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.466457</td>\n",
       "      <td>0.026088</td>\n",
       "      <td>-0.499298</td>\n",
       "      <td>-0.674372</td>\n",
       "      <td>-0.144883</td>\n",
       "      <td>-1.178075</td>\n",
       "      <td>0.058089</td>\n",
       "      <td>-0.420145</td>\n",
       "      <td>-1.359651</td>\n",
       "      <td>0.210249</td>\n",
       "      <td>-0.033777</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>1.767471</td>\n",
       "      <td>-1.212943</td>\n",
       "      <td>0.427684</td>\n",
       "      <td>1.252714</td>\n",
       "      <td>0.843412</td>\n",
       "      <td>-1.534474</td>\n",
       "      <td>0.830734</td>\n",
       "      <td>0.207653</td>\n",
       "      <td>-0.234087</td>\n",
       "      <td>-0.710542</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>-0.174713</td>\n",
       "      <td>0.533719</td>\n",
       "      <td>-0.454779</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.030935</td>\n",
       "      <td>-0.309419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.922137</td>\n",
       "      <td>-0.371579</td>\n",
       "      <td>2.132018</td>\n",
       "      <td>-0.796997</td>\n",
       "      <td>0.324175</td>\n",
       "      <td>-1.162006</td>\n",
       "      <td>0.277208</td>\n",
       "      <td>-0.249586</td>\n",
       "      <td>-0.775648</td>\n",
       "      <td>-0.061757</td>\n",
       "      <td>-0.959725</td>\n",
       "      <td>0.408746</td>\n",
       "      <td>0.597641</td>\n",
       "      <td>-0.802430</td>\n",
       "      <td>-1.889520</td>\n",
       "      <td>-1.607785</td>\n",
       "      <td>-0.401475</td>\n",
       "      <td>0.729773</td>\n",
       "      <td>-2.445693</td>\n",
       "      <td>-0.461062</td>\n",
       "      <td>-0.302654</td>\n",
       "      <td>-0.246899</td>\n",
       "      <td>-0.045745</td>\n",
       "      <td>0.677110</td>\n",
       "      <td>0.016109</td>\n",
       "      <td>-0.734220</td>\n",
       "      <td>-0.034480</td>\n",
       "      <td>-0.064786</td>\n",
       "      <td>-0.321051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.166525</td>\n",
       "      <td>0.255439</td>\n",
       "      <td>2.108464</td>\n",
       "      <td>0.135019</td>\n",
       "      <td>-0.072979</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>0.755918</td>\n",
       "      <td>0.355528</td>\n",
       "      <td>-0.422820</td>\n",
       "      <td>-0.842826</td>\n",
       "      <td>0.663538</td>\n",
       "      <td>0.624657</td>\n",
       "      <td>0.107262</td>\n",
       "      <td>-0.073654</td>\n",
       "      <td>-0.305506</td>\n",
       "      <td>0.618642</td>\n",
       "      <td>-0.952529</td>\n",
       "      <td>0.757618</td>\n",
       "      <td>-0.375461</td>\n",
       "      <td>0.353355</td>\n",
       "      <td>0.136470</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>0.121017</td>\n",
       "      <td>0.636266</td>\n",
       "      <td>0.492943</td>\n",
       "      <td>-0.750242</td>\n",
       "      <td>0.029124</td>\n",
       "      <td>0.091303</td>\n",
       "      <td>0.346316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "Index                                                                         \n",
       "0      2.245295 -1.160960 -1.966682 -1.430190 -0.607246 -1.508696 -0.074415   \n",
       "1      1.278609  0.102574  0.512079  0.003930 -0.723474 -1.334105  0.029958   \n",
       "2      1.466457  0.026088 -0.499298 -0.674372 -0.144883 -1.178075  0.058089   \n",
       "3     -0.922137 -0.371579  2.132018 -0.796997  0.324175 -1.162006  0.277208   \n",
       "4     -1.166525  0.255439  2.108464  0.135019 -0.072979  0.910821  0.755918   \n",
       "\n",
       "             V8        V9       V10       V11       V12       V13       V14  \\\n",
       "Index                                                                         \n",
       "0     -0.655096 -1.970141  1.607283 -0.780267 -0.294928  1.236719 -0.135565   \n",
       "1     -0.296595  0.128119 -0.209865  0.188511  0.674525  0.712608  0.122319   \n",
       "2     -0.420145 -1.359651  0.210249 -0.033777 -0.001594  1.767471 -1.212943   \n",
       "3     -0.249586 -0.775648 -0.061757 -0.959725  0.408746  0.597641 -0.802430   \n",
       "4      0.355528 -0.422820 -0.842826  0.663538  0.624657  0.107262 -0.073654   \n",
       "\n",
       "            V15       V16       V17       V18       V19       V20       V21  \\\n",
       "Index                                                                         \n",
       "0     -0.832677 -1.400205  0.807960 -0.670317 -0.044106 -0.292081  0.010490   \n",
       "1      1.038024  0.128638 -0.222614 -0.687546 -0.056504 -0.040015 -0.081470   \n",
       "2      0.427684  1.252714  0.843412 -1.534474  0.830734  0.207653 -0.234087   \n",
       "3     -1.889520 -1.607785 -0.401475  0.729773 -2.445693 -0.461062 -0.302654   \n",
       "4     -0.305506  0.618642 -0.952529  0.757618 -0.375461  0.353355  0.136470   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Index                                                                         \n",
       "0      0.521714 -0.064971  0.048849  0.383290  0.103970 -0.047350 -0.064800   \n",
       "1     -0.182506  0.078986  0.789993  0.219794  0.938359 -0.078720  0.008119   \n",
       "2     -0.710542 -0.001242 -0.174713  0.533719 -0.454779  0.001524  0.030935   \n",
       "3     -0.246899 -0.045745  0.677110  0.016109 -0.734220 -0.034480 -0.064786   \n",
       "4      0.017496  0.121017  0.636266  0.492943 -0.750242  0.029124  0.091303   \n",
       "\n",
       "         Amount  Class  \n",
       "Index                   \n",
       "0     -0.054400      0  \n",
       "1     -0.347672      0  \n",
       "2     -0.309419      0  \n",
       "3     -0.321051      0  \n",
       "4      0.346316      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Data\n",
    "X = df.drop(['Class'], axis =1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buliding the model to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling the imbalanced data by using smote technique\n",
    "oversample = SMOTE()\n",
    "X_sample , y_sample = oversample.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((568030, 29), (568030,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape,y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test  = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test  = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim = 29, units=16, activation = 'relu',kernel_initializer='he_uniform'))    #adding input layer\n",
    "model.add(Dense(units = 24, activation = 'relu',kernel_initializer='he_uniform'))                  #adding 2nd hidden layer\n",
    "model.add(Dropout(0.5))                                                                            #adding dropout layer\n",
    "model.add(Dense(units = 20, activation = 'relu',kernel_initializer='he_uniform'))                  #adding 3rd hidden layer\n",
    "model.add(Dropout(0.5))                                                                            #adding dropout layer\n",
    "model.add(Dense(units = 24, activation = 'relu',kernel_initializer='he_uniform'))                  #adding 4th hidden layer\n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(units = 20, activation = 'relu',kernel_initializer='he_uniform'))                  #adding 5th hidden layer\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))                                                #adding output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,413\n",
      "Trainable params: 2,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python27\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Python27\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "397621/397621 [==============================] - 179s 450us/step - loss: 0.1013 - accuracy: 0.9652\n",
      "Epoch 2/10\n",
      "397621/397621 [==============================] - 178s 448us/step - loss: 0.0305 - accuracy: 0.9921\n",
      "Epoch 3/10\n",
      "397621/397621 [==============================] - 180s 453us/step - loss: 0.0220 - accuracy: 0.9948\n",
      "Epoch 4/10\n",
      "397621/397621 [==============================] - 181s 454us/step - loss: 0.0196 - accuracy: 0.9957\n",
      "Epoch 5/10\n",
      "397621/397621 [==============================] - 180s 453us/step - loss: 0.0180 - accuracy: 0.9963\n",
      "Epoch 6/10\n",
      "397621/397621 [==============================] - 181s 454us/step - loss: 0.0173 - accuracy: 0.9964\n",
      "Epoch 7/10\n",
      "397621/397621 [==============================] - 182s 458us/step - loss: 0.0172 - accuracy: 0.9966\n",
      "Epoch 8/10\n",
      "397621/397621 [==============================] - 184s 464us/step - loss: 0.0175 - accuracy: 0.9965\n",
      "Epoch 9/10\n",
      "397621/397621 [==============================] - 184s 462us/step - loss: 0.0167 - accuracy: 0.9966\n",
      "Epoch 10/10\n",
      "397621/397621 [==============================] - 185s 465us/step - loss: 0.0205 - accuracy: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a90916d4c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170409/170409 [==============================] - 10s 61us/step\n",
      "[0.011805690529994821, 0.9976409673690796]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84775   344]\n",
      " [   58 85232]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred.round())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  0.997640969667095\n",
      "f1 Score :  0.9976472791544251\n",
      "precision score :  0.9959801813592596\n",
      "Recall Score :  0.9993199671708289\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score : \", accuracy_score(y_test, y_pred.round()))\n",
    "print(\"f1 Score : \", f1_score(y_test, y_pred.round()))\n",
    "print(\"precision score : \", precision_score(y_test, y_pred.round()))\n",
    "print(\"Recall Score : \", recall_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('TEST.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.99999714],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.9999999 ],\n",
       "       [0.00140581],\n",
       "       [0.9999996 ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [1.        ],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581],\n",
       "       [0.00140581]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.index.name = 'Index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.columns = ['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Class\n",
       "Index          \n",
       "0      0.001406\n",
       "1      0.001406\n",
       "2      0.001406\n",
       "3      0.999997\n",
       "4      0.001406\n",
       "...         ...\n",
       "347    0.001406\n",
       "348    0.001406\n",
       "349    0.001406\n",
       "350    0.001406\n",
       "351    0.001406\n",
       "\n",
       "[352 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('predict_Outputs.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
